{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "from string import punctuation\n",
    "import timeit\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "import codecs\n",
    "# import necessary NLTK packages\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import custom libraries\n",
    "from MongoConnector import MongoConnector\n",
    "from PyContract import PyContract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIRECTORY = '../output'\n",
    "TV_SHOW = 'NCISNOLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {  'MONGO_COLL': 'NCISNOLA',\n",
    "            'MONGO_DB': 'swati_dataset',\n",
    "            'MONGO_HOST': 'localhost',\n",
    "            'MONGO_PORT': 27017}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customWords = ['bc', 'http', 'https', 'co', 'com','rt', 'one', 'us', 'new', \n",
    "              'lol', 'may', 'get', 'want', 'like', 'love', 'no', 'thank', 'would', 'thanks',\n",
    "              'good', 'much', 'low', 'roger', 'im']\n",
    "alphabets = list(map(chr, range(97, 123)))\n",
    "myStopWords = set(stopwords.words('english') + list(punctuation) + customWords + alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dbconnector, contracters, tokenizers, lemmatizers\n",
    "dbconnector = MongoConnector(config)\n",
    "contracter = PyContract()\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tweets(user:str) -> list:\n",
    "    '''\n",
    "        This function takes the config file and connects to MongoDB collection.\n",
    "        Retrieves the tweet list from the user id and returns a dict object\n",
    "\n",
    "        Output: {'user_id' : [tweet_list]}\n",
    "    '''\n",
    "    # Create new mongo collection and cursor object to store the unprocessed raw feature corpus\n",
    "    cursor = dbconnector.__connect__()\n",
    "    # Collect all the user tweets as one document and store it in a list\n",
    "    que = cursor.find({'user.id_str':user, 'lang':'en'}, {'_id':0, 'text':1})\n",
    "    if que.count() < 10:\n",
    "        return None\n",
    "    tweet_list = list()\n",
    "    for tweet in que:\n",
    "        tweet_list.append(contracter.__translate__(tweet['text']))\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_Tweets(tweet_list:list) -> list:\n",
    "    # Pre-process step 1 - Word Tokenization\n",
    "    \n",
    "    # 1. Word Tokenization\n",
    "    words = list(tokenizer.tokenize(tweets) for tweets in tweet_list)\n",
    "    print(words[:5])\n",
    "\n",
    "    # 2. Remove the stop words from the document\n",
    "    words_steps2 = list()\n",
    "    for tweet in words: \n",
    "        sents = list(re.sub(r'\\W+', '', word) for word in tweet)\n",
    "        sents = filter(lambda s: not str(s).lstrip('-').isdigit(), sents)   \n",
    "        sents = list(word for word in sents if word not in myStopWords and word!='' and \n",
    "                                                                    not word.startswith('http'))\n",
    "        if sents!= None:\n",
    "            words_steps2.append(sents)\n",
    "    print(words_steps2[:5])\n",
    "\n",
    "    # Pre-process step3 - Lemmatization\n",
    "    pre_processed_list = list()\n",
    "    for tweet in words_steps2:\n",
    "        words_step4 = list()\n",
    "        words_step3 = pos_tag(tweet)\n",
    "        for token in words_step3:\n",
    "            pos = get_wordnet_pos(token[1])\n",
    "            # if verb, noun, adj or adverb include them after lemmatization\n",
    "            if pos is not None and len(token[0]) > 3:\n",
    "                try:\n",
    "                    tok = lemmatizer.lemmatize(token[0], pos)\n",
    "                    words_step4.append(tok)              \n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "        if(words_step4 != [] and words_step4!='\\n'): \n",
    "            pre_processed_list.append(\" \".join(words_step4))\n",
    "        else:\n",
    "            continue\n",
    "    print(pre_processed_list[:5])\n",
    "    return pre_processed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users():\n",
    "    cursor = dbconnector.__connect__()\n",
    "    # Collect all the user tweets as one document and store it in a list\n",
    "    que = cursor.distinct('user.id_str')\n",
    "    unique_users_list = list(que)\n",
    "    return unique_users_list\n",
    "    \n",
    "    \n",
    "def ensure_directory():\n",
    "    if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "        os.makedirs(OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the unique users list.....\n",
      "Successfully imported 6325 unique users....\n",
      "\n",
      "['rt @ncisneworleans: .@thelucasblack explains why you need to watch #ncisnola tonight!\\nhttps://t.co/bzegf4zpmy', 'rt @ncisneworleans: look who stopped by the #ncisnola truck... @hwinkler4real!! do not miss the series premiere tonight after @ncis_cbs! htt…', 'rt @thetalk_cbs: video: @scottbakula discusses the premiere of his new show, @ncisneworleans, with the ladies! http://t.co/vvzfbtffpq #thet…', 'rt @ncisneworleans: the series premiere of #ncisnola is so close! use this translator while watching the show. http://t.co/ps7hbgkngn', 'rt @ncisneworleans: the series premiere of #ncisnola starts in 10 minutes on cbs! time to get to work. sneak peek: http://t.co/x66168lxam']\n",
      "[['rt', ':', '.', 'explains', 'why', 'you', 'need', 'to', 'watch', '#ncisnola', 'tonight', '!', 'https://t.co/bzegf4zpmy'], ['rt', ':', 'look', 'who', 'stopped', 'by', 'the', '#ncisnola', 'truck', '...', '!', '!', 'do', 'not', 'miss', 'the', 'series', 'premiere', 'tonight', 'after', '!', 'htt', '…'], ['rt', ':', 'video', ':', 'discusses', 'the', 'premiere', 'of', 'his', 'new', 'show', ',', ',', 'with', 'the', 'ladies', '!', 'http://t.co/vvzfbtffpq', '#thet', '…'], ['rt', ':', 'the', 'series', 'premiere', 'of', '#ncisnola', 'is', 'so', 'close', '!', 'use', 'this', 'translator', 'while', 'watching', 'the', 'show', '.', 'http://t.co/ps7hbgkngn'], ['rt', ':', 'the', 'series', 'premiere', 'of', '#ncisnola', 'starts', 'in', '10', 'minutes', 'on', 'cbs', '!', 'time', 'to', 'get', 'to', 'work', '.', 'sneak', 'peek', ':', 'http://t.co/x66168lxam']]\n",
      "[['explains', 'need', 'watch', 'ncisnola', 'tonight'], ['look', 'stopped', 'ncisnola', 'truck', 'miss', 'series', 'premiere', 'tonight', 'htt'], ['video', 'discusses', 'premiere', 'show', 'ladies', 'thet'], ['series', 'premiere', 'ncisnola', 'close', 'use', 'translator', 'watching', 'show'], ['series', 'premiere', 'ncisnola', 'starts', 'minutes', 'cbs', 'time', 'work', 'sneak', 'peek']]\n",
      "['explains need watch ncisnola tonight', 'look stop ncisnola truck miss series premiere tonight', 'video discus premiere show lady thet', 'series premiere ncisnola close translator watch show', 'series ncisnola start minute time work sneak peek']\n",
      "----> Pre-processing complete...\n",
      "21973050|explains need watch ncisnola tonight\n",
      "explains need watch ncisnola tonight\n",
      "21973050|look stop ncisnola truck miss series premiere tonight\n",
      "look stop ncisnola truck miss series premiere tonight\n",
      "21973050|video discus premiere show lady thet\n",
      "video discus premiere show lady thet\n",
      "21973050|series premiere ncisnola close translator watch show\n",
      "series premiere ncisnola close translator watch show\n",
      "21973050|series ncisnola start minute time work sneak peek\n",
      "series ncisnola start minute time work sneak peek\n",
      "21973050|ncisnola ncisneworleans\n",
      "ncisnola ncisneworleans\n",
      "21973050|great scott bakula ncisnola\n",
      "great scott bakula ncisnola\n",
      "21973050|wonderful back screen ncisnola gonna\n",
      "wonderful back screen ncisnola gonna\n",
      "21973050|time roll ncisnola time tweet\n",
      "time roll ncisnola time tweet\n",
      "21973050|lovin know\n",
      "lovin know\n",
      "21973050|cast crew live tweet series premiere ncisnola join convo\n",
      "cast crew live tweet series premiere ncisnola join convo\n",
      "21973050|ncisnola minute home choose cast\n",
      "ncisnola minute home choose cast\n",
      "21973050|okay ncisnola promise sings upcoming episode piano enough\n",
      "okay ncisnola promise sings upcoming episode piano enough\n",
      "21973050|ncisnola premier viewer hold ncis leadin ncis mostwatched show nite viewer\n",
      "ncisnola premier viewer hold ncis leadin ncis mostwatched show nite viewer\n",
      "21973050|wait watch ncisnola series premiere\n",
      "wait watch ncisnola series premiere\n",
      "21973050|prankster ncisnola answer question\n",
      "prankster ncisnola answer question\n",
      "21973050|pride mindful even think gator ncisnola sneak peek\n",
      "pride mindful even think gator ncisnola sneak peek\n",
      "21973050|boomboomboom ncisnola boom boom boom\n",
      "boomboomboom ncisnola boom boom boom\n",
      "21973050|brenda brandons ncisnola beverlyhills90210\n",
      "brenda brandons ncisnola beverlyhills90210\n",
      "21973050|prisoner escape armored transport carry naval brig detainee ncisnola look\n",
      "prisoner escape armored transport carry naval brig detainee ncisnola look\n",
      "21973050|manhunt minute ncisnola sneak peek\n",
      "manhunt minute ncisnola sneak peek\n",
      "21973050|seriously scott bakula ncisnola great choice lead\n",
      "seriously scott bakula ncisnola great choice lead\n",
      "21973050|gibbs ncisnola\n",
      "gibbs ncisnola\n",
      "21973050|problem cannot solve full episode\n",
      "problem cannot solve full episode\n",
      "21973050|everyone little help ncisnola ncis\n",
      "everyone little help ncisnola ncis\n",
      "21973050|happybirthday\n",
      "happybirthday\n",
      "21973050|back school ncisnola team investigate navy seal murder sorority house preview\n",
      "back school ncisnola team investigate navy seal murder sorority house preview\n",
      "21973050|ncisnola tunnel level\n",
      "ncisnola tunnel level\n",
      "21973050|ncisnola sebastian dorm captain fitting\n",
      "ncisnola sebastian dorm captain fitting\n",
      "21973050|ncisnola conspiracy discernment\n",
      "ncisnola conspiracy discernment\n",
      "21973050|ncisnola oooh agent pride get piano\n",
      "ncisnola oooh agent pride get piano\n",
      "21973050|ncisnola fight damn brody youshouldseeherwhenshesangry\n",
      "ncisnola fight damn brody youshouldseeherwhenshesangry\n",
      "21973050|ncisnola hell already pretty busy pas\n",
      "ncisnola hell already pretty busy pas\n",
      "21973050|ncisnola easy wash gunshot residue hand ignore tweet\n",
      "ncisnola easy wash gunshot residue hand ignore tweet\n",
      "21973050|ncisnola collegiate call girl\n",
      "ncisnola collegiate call girl\n",
      "21973050|ncisnola please pride piano\n",
      "ncisnola please pride piano\n",
      "21973050|ncisnola chill spill\n",
      "ncisnola chill spill\n",
      "21973050|ncisnola sugar overload\n",
      "ncisnola sugar overload\n",
      "21973050|ncisnola always campus security dude\n",
      "ncisnola always campus security dude\n",
      "21973050|ncisnola\n",
      "ncisnola\n",
      "21973050|ncisnola fold honor foundation mention cool\n",
      "ncisnola fold honor foundation mention cool\n",
      "21973050|ncisnola pride piano sing\n",
      "ncisnola pride piano sing\n",
      "21973050|ncisnola pride play piano sing make sense\n",
      "ncisnola pride play piano sing make sense\n",
      "21973050|follow ncisnola begin cbsallaccess stream episode device week free\n",
      "follow ncisnola begin cbsallaccess stream episode device week free\n",
      "21973050|tomorrow team investigate murder navy officer level security clearance preview\n",
      "tomorrow team investigate murder navy officer level security clearance preview\n",
      "21973050|petty officer murder apparent marriage proposal girlfriend first look\n",
      "petty officer murder apparent marriage proposal girlfriend first look\n",
      "21973050|tuesday look cold case lorettas past still keep night\n",
      "tuesday look cold case lorettas past still keep night\n",
      "21973050|first monday backtowork holidaze ncisnola caseofthemondays\n",
      "first monday backtowork holidaze ncisnola caseofthemondays\n",
      "21973050|ncisnola back tomorrow night excite preview\n",
      "ncisnola back tomorrow night excite preview\n",
      "21973050|ncisnola year powerful episode watch\n",
      "ncisnola year powerful episode watch\n",
      "21973050|friend turn pride solve murder case tomorrow ncisnola\n",
      "friend turn pride solve murder case tomorrow ncisnola\n",
      "21973050|guess fan ncisnola watch drama year read\n",
      "guess fan ncisnola watch drama year read\n",
      "21973050|friend pride asks solve murder full\n",
      "friend pride asks solve murder full\n",
      "21973050|dive brodys mysterious past find happen moultrie ncisnola look\n",
      "dive brodys mysterious past find happen moultrie ncisnola look\n",
      "21973050|boomboomboomboom bangbangbangbang know mean ncisnola join conversation\n",
      "boomboomboomboom bangbangbangbang know mean ncisnola join conversation\n",
      "21973050|look milk group go sour ncisnola\n",
      "look milk group go sour ncisnola\n",
      "21973050|whatislovein4words call pride ncisnola\n",
      "whatislovein4words call pride ncisnola\n",
      "21973050|happy valentinesday ncisnola\n",
      "happy valentinesday ncisnola\n",
      "21973050|ncisnola episode wait mardigras sneak peek\n",
      "ncisnola episode wait mardigras sneak peek\n",
      "21973050|special mardigras fattuesday ncisnola start minute\n",
      "special mardigras fattuesday ncisnola start minute\n",
      "21973050|aboard tuesday happy mardi gras fattuesday mardigras ncisnola\n",
      "aboard tuesday happy mardi gras fattuesday mardigras ncisnola\n",
      "21973050|boomboomboomboom bangbangbangbang ncisnola join fattuesday mardigras celebration\n",
      "boomboomboomboom bangbangbangbang ncisnola join fattuesday mardigras celebration\n",
      "21973050|illustrious stacy keach lady gentlemen ncisnola\n",
      "illustrious stacy keach lady gentlemen ncisnola\n",
      "21973050|great freak show earth ncisnola\n",
      "great freak show earth ncisnola\n",
      "21973050|intergalatic krewe chewbacchus represent ncisnola\n",
      "intergalatic krewe chewbacchus represent ncisnola\n",
      "21973050|use actual wookie translator next ncisnola\n",
      "use actual wookie translator next ncisnola\n",
      "21973050|grandpa pride somethings pride daughter act suspicious ncisnola\n",
      "grandpa pride somethings pride daughter act suspicious ncisnola\n",
      "21973050|know anything mardi gras related something pride\n",
      "know anything mardi gras related something pride\n",
      "21973050|great scene pride laurel ncisnola\n",
      "great scene pride laurel ncisnola\n",
      "21973050|tick tock tick tock ncisnola\n",
      "tick tock tick tock ncisnola\n",
      "21973050|boom partysover ncisnola\n",
      "boom partysover ncisnola\n",
      "21973050|spending fattuesday happy mardigras ncisnola\n",
      "spending fattuesday happy mardigras ncisnola\n",
      "21973050|tomorrow night episode super brothery include return lasalle cade mucho fantastic retweet\n",
      "tomorrow night episode super brothery include return lasalle cade mucho fantastic retweet\n",
      "21973050|emotion fall ncisnola also always live tweet sharewithyourfriends\n",
      "emotion fall ncisnola also always live tweet sharewithyourfriends\n",
      "21973050|patton plame triplep kevlar get serious ncisnola\n",
      "patton plame triplep kevlar get serious ncisnola\n",
      "21973050|great profile baitfish back ncisnola look\n",
      "great profile baitfish back ncisnola look\n",
      "21973050|tonight ncisnola pride\n",
      "tonight ncisnola pride\n",
      "21973050|live blogging tonight ncisnola usual retweet puppy make sure ready\n",
      "live blogging tonight ncisnola usual retweet puppy make sure ready\n",
      "21973050|pride hunt tonight ncisnola\n",
      "pride hunt tonight ncisnola\n",
      "21973050|baitfish back ncisnola start minute\n",
      "baitfish back ncisnola start minute\n",
      "21973050|first previously ncisnola\n",
      "first previously ncisnola\n",
      "21973050|ncis orleans tonight baitfish return catch someone give ncisnola\n",
      "ncis orleans tonight baitfish return catch someone give ncisnola\n",
      "21973050|baaack ncisnola\n",
      "baaack ncisnola\n",
      "21973050|boomboomboomboom bangbangbangbang ncisnola join conversation\n",
      "boomboomboomboom bangbangbangbang ncisnola join conversation\n",
      "21973050|part episode know finally go start explore pride room\n",
      "part episode know finally go start explore pride room\n",
      "21973050|pride piano gotta play sing ncisnola\n",
      "pride piano gotta play sing ncisnola\n",
      "21973050|tomato stole patton call see always ncisnola\n",
      "tomato stole patton call see always ncisnola\n",
      "21973050|pattons worry dude data plan ncisnola\n",
      "pattons worry dude data plan ncisnola\n",
      "21973050|wall crazy person publicserviceannouncement ncisnola\n",
      "wall crazy person publicserviceannouncement ncisnola\n",
      "21973050|go long piano happy back ncisnola\n",
      "go long piano happy back ncisnola\n",
      "21973050|nice touch piano ncisnola\n",
      "nice touch piano ncisnola\n",
      "21973050|clinic goneandgone ncisnola\n",
      "clinic goneandgone ncisnola\n",
      "21973050|mornin wait shower ncisnola\n",
      "mornin wait shower ncisnola\n",
      "21973050|baitfish back chase continue watch last night episode ncisnola\n",
      "baitfish back chase continue watch last night episode ncisnola\n",
      "1. Pre-processed tweets for userid: 21973050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Thesis/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Make sure directory is present. If not create the directory - 'output'\n",
    "    with codecs.open(OUTPUT_DIRECTORY+'/'+TV_SHOW+\"_raw_tweets_with_userid.csv\", 'w','utf-8') as raw_u_file, \\\n",
    "           codecs.open(OUTPUT_DIRECTORY+'/'+TV_SHOW+\"_preprocessed_tweets_corpora.csv\", 'w','utf-8') as preproc_file, \\\n",
    "             codecs.open(OUTPUT_DIRECTORY+'/'+TV_SHOW+\"_preprocessed_tweets_with_userid.csv\", 'w','utf-8') as preproc_u_file, \\\n",
    "               codecs.open(OUTPUT_DIRECTORY+'/'+TV_SHOW+\"_preprocessed_tweets_1by1__with_userid.csv\", 'w','utf-8') as preproc_line_file, \\\n",
    "                 codecs.open(OUTPUT_DIRECTORY+'/'+TV_SHOW+\"_discarded_users_list.csv\", 'w','utf-8') as discarded_users_file:\n",
    "\n",
    "        # Load the unique users from the file into a list given by unique_users_list\n",
    "        print(\"Importing the unique users list.....\")\n",
    "        unique_users_list = get_users()\n",
    "        discarded_users_list = list()\n",
    "        print(\"Successfully imported {0} unique users....\\n\".format(len(unique_users_list)))\n",
    "     \n",
    "        # Get tweets for each unique user\n",
    "        counter = 1\n",
    "        total_tweets = 0\n",
    "        total_pre_processed_tweets = 0\n",
    "        for user in unique_users_list:\n",
    "            user_start_time = timeit.default_timer()\n",
    "    \n",
    "            tweet_list = get_Tweets(user)\n",
    "            print(tweet_list[:5])\n",
    "            if tweet_list is None:\n",
    "                print.debug(\"Discarded userid : {}\\n\".format(user))\n",
    "                discarded_users_list.append(user)\n",
    "                counter+=1\n",
    "                continue\n",
    "            processed_tweet_list = preprocess_Tweets(tweet_list)\n",
    "            print(\"----> Pre-processing complete...\")\n",
    "            \n",
    "\n",
    "            for tweet in processed_tweet_list:\n",
    "                print(\"{0}|{1}\".format(user, tweet))\n",
    "                print(\"{0}\".format(tweet))      \n",
    "            user_end_time = timeit.default_timer()\n",
    " \n",
    "            total_tweets += len(tweet_list)\n",
    "            total_pre_processed_tweets += len(processed_tweet_list)\n",
    "            print('{0}. Pre-processed tweets for userid: {1}'.format(counter, user))\n",
    "            counter+=1\n",
    "            break\n",
    "\n",
    "###########     MAIN  PROGRAM ENDS HERE    ##########ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
