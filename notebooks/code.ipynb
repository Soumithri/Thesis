{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from gensim import corpora, models, matutils\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from scipy.spatial.distance import cdist\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_values import (\n",
    "    TV_SHOW, \n",
    "    PRE_PROCESSED_FILE_NAME, \n",
    "    LDA_FILE_NAME, \n",
    "    OUT_DIR, \n",
    "    GAMMA, \n",
    "    TOLERANCE, \n",
    "    ITERATIONS, \n",
    "    NUM_TOPICS,\n",
    "    GRAPHML_FILE,\n",
    "    GRAPH_NODE_FILE,\n",
    "    TOPIC_VEC_FILE,\n",
    "    TWITTER_RANK_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('YouNetflix_new',\n",
       " 'YouNetflix_new',\n",
       " '../tvshows/output/YouNetflix_new.graphml',\n",
       " 'YouNetflix_new_graph_nodes_with_no_isolated_nodes.csv',\n",
       " 'YouNetflix_new_topic_frame.csv',\n",
       " 'YouNetflix_new_topic_rank_frame.csv',\n",
       " '../tvshows/output/YouNetflix_new.graphml')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_SHOW, PRE_PROCESSED_FILE_NAME,GRAPHML_FILE, GRAPH_NODE_FILE, TOPIC_VEC_FILE, TWITTER_RANK_FILE, GRAPHML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_INFLUENTIAL_NODES = 100\n",
    "threshold_percentile_for_merge = 25\n",
    "threshold_percentile_for_split = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolated_nodes(G):\n",
    "    print(nx.info(G))\n",
    "    isolated_nodes = list(nx.isolates(G))\n",
    "    print('\\nIsolated nodes: {}\\n'.format(len(isolated_nodes)))\n",
    "    print('removing isolated nodes...\\n')\n",
    "    G.remove_nodes_from(isolated_nodes)\n",
    "    #G = G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    return G\n",
    "\n",
    "def load_graph(graph_file = GRAPHML_FILE):\n",
    "\n",
    "    graph = nx.read_graphml(GRAPHML_FILE)\n",
    "    print(nx.info(graph))\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def write_graph(G, graph_file):\n",
    "    nx.write_graphml(G, graph_file)\n",
    "    \n",
    "def add_weights(graph):\n",
    "    degree_list = ['retweet_count', 'mention_count', 'reply_count', 'quote_count']\n",
    "    attrs = {}\n",
    "    for (node1,node2,*data) in graph.edges(data=True):\n",
    "        weight = sum([value for key, value in data[0].items() if key in degree_list])\n",
    "        attrs[(node1, node2)] = {'weight': weight}\n",
    "    nx.set_edge_attributes(graph, attrs)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataframes :-\n",
    "## user_id_df, graph_nodes_df, twitter_rank_df, topic_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_frame(file, graph_node_file=GRAPH_NODE_FILE):\n",
    "    graph = pd.read_csv(graph_node_file)\n",
    "    graph = graph.rename(columns = {'Unnamed: 0':'userid'})\n",
    "    topic = pd.read_csv(file)\n",
    "    topic = topic.rename(columns = {'Unnamed: 0':'userid'})\n",
    "    columns = topic.columns\n",
    "    new = pd.merge(graph,topic,on = 'userid',how = 'left')\n",
    "    dic = {'0_x':'0_y','1_x':'1_y','2_x':'2_y','3_x':'3_y','4_x':'4_y','5_x':'5_y',\n",
    "           '6_x':'6_y','6_x':'6_y','7_x':'7_y','8_x':'8_y','9_x':'9_y'}\n",
    "    for i in dic:\n",
    "        new[i] = new[i] + new[dic[i]]\n",
    "    new = new.drop(columns = dic.values())\n",
    "    new.fillna(0.1, inplace=True)\n",
    "    new.set_index('userid', inplace=True)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(GRAPH_NODE_FILE).index.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection algorithm below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_influential_nodes(graph, df, twitter_rank_df, num_topics=NUM_TOPICS, \n",
    "                          num_of_influential_nodes=NUM_OF_INFLUENTIAL_NODES):\n",
    "    topic_rank = twitter_rank_df.values\n",
    "    topic_rank_sum = np.sum(topic_rank/num_topics, axis=1)\n",
    "    average_twitter_rank = np.array(topic_rank_sum[:])\n",
    "\n",
    "    df['avg_twitter_rank'] = average_twitter_rank\n",
    "    influential_nodes_index = np.argsort(average_twitter_rank, axis=0).reshape(\n",
    "        len(average_twitter_rank),1)[:num_of_influential_nodes, :]\n",
    "\n",
    "    influential_nodes_index = [int(i) for i in influential_nodes_index]\n",
    "    influential_nodes = df.iloc[influential_nodes_index].index.tolist()\n",
    "    \n",
    "    return influential_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Community detection algorithm here\n",
    "\n",
    "def step1_assign_initial_communities(graph, df, influential_nodes):\n",
    "    # Initial community assignment\n",
    "    influential_nodes = [int(i) for i in influential_nodes]\n",
    "    communities = {k: [k] for k in influential_nodes}\n",
    "\n",
    "    # Remaining nodes\n",
    "    remaining_nodes = set(df.index) - set(influential_nodes)\n",
    "\n",
    "    # Get the weighted adjacency matrix\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph, weight='weight').todense()\n",
    "    adjacency_matrix_df = pd.DataFrame(data=adjacency_matrix, index=df.index, \n",
    "                                       columns=df.index)\n",
    "    #print(adjacency_matrix_df)\n",
    "\n",
    "    # Get nodes weight with influential users\n",
    "    nodes_weight_with_influential_nodes_df = adjacency_matrix_df[influential_nodes]\n",
    "    nodes_weight_with_influential_nodes_df['max_weight_with_influencer'] = nodes_weight_with_influential_nodes_df[\n",
    "        nodes_weight_with_influential_nodes_df > 0].idxmax(axis=1)\n",
    "    nodes_weight_with_influential_nodes_df['max_weight_with_influencer'].fillna(False, inplace=True)\n",
    "    # Main algorithm here\n",
    "\n",
    "\n",
    "    for node in remaining_nodes:\n",
    "      # add this node to an influencerâ€™s community if this influencer \n",
    "      # and this node have the highest edge weight\n",
    "      influencer_with_max_weight_with_node = nodes_weight_with_influential_nodes_df[\n",
    "          'max_weight_with_influencer'].loc[node]\n",
    "      if isinstance(influencer_with_max_weight_with_node, np.int64):\n",
    "        communities[influencer_with_max_weight_with_node].append(node)\n",
    "    \n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim_df(df):\n",
    "    topic_vectors = df.values\n",
    "    #print(df.values.shape)\n",
    "    norm_topic_vectors = topic_vectors / np.linalg.norm(topic_vectors, axis=-1)[:, np.newaxis]\n",
    "    cosine_sim = np.dot(norm_topic_vectors, norm_topic_vectors.T)\n",
    "    cosine_sim_df = pd.DataFrame(data = cosine_sim, index=df.index, columns=df.index)\n",
    "    return cosine_sim_df\n",
    "\n",
    "def step2_split_community(communities, threshold_percentile_for_split, cosine_sim_df):\n",
    "\n",
    "    # Split these initial communities based on topic vectors.  \n",
    "    # Given a community of m nodes, we can compute the pairwise cosine-distance of \n",
    "    # the topical vectors. This will give us m(m-2)/2 distances.  \n",
    "    # We then remove a node if its cosine distances from all its neighbors \n",
    "    # are below a threshold, say, the first quartile of all the m(m-2)/2 distances.\n",
    "\n",
    "\n",
    "    #topic_vectors = df.values\n",
    "    #cosine_sim = np.array([]).reshape(len(df),0)\n",
    "    #if os.path.isfile(TV_SHOW + '_cosine_sim_frame.csv'+ str(len(communities)) +\n",
    "    #                  str(threshold_percentile_for_split)+ '.csv'):\n",
    "    #    cosine_sim_df = \n",
    "    #for k, node in enumerate(df.index.tolist()):\n",
    "    #  #cosine_sim = np.c_[cosine_sim, 1 - cdist(topic_vectors, np.matrix(df.loc[node])[:,:NUM_TOPICS], \n",
    "    #  #                                         metric='cosine')]\n",
    "    #  b = np.matrix(df.loc[node])[:,:NUM_TOPICS]\n",
    "    #  cosine_sim = np.c_[cosine_sim , np.dot(topic_vectors, b.T) / np.outer(np.linalg.norm(topic_vectors, axis=1), \n",
    "    #                                                                        np.linalg.norm(b, axis=1))]\n",
    "    #  if k % 5000 == 0:\n",
    "    #        print('cosine_sim with {} nodes done'.format(k))\n",
    "    #cosine_sim_df = pd.DataFrame(data=cosine_sim, index=df.index, columns=df.index)\n",
    "    \n",
    "    #topic_vectors = df.values\n",
    "    #print(df.values.shape)\n",
    "    #norm_topic_vectors = topic_vectors / np.linalg.norm(topic_vectors, axis=-1)[:, np.newaxis]\n",
    "    #cosine_sim = np.dot(norm_topic_vectors, norm_topic_vectors.T)\n",
    "    #cosine_sim_df = pd.DataFrame(data = cosine_sim, index=df.index, columns=df.index)\n",
    "    #cosine_sim_df.to_csv(TV_SHOW + '_cosine_sim_frame.csv'+ str(len(communities)) + \n",
    "    #                     str(threshold_percentile_for_split)+ '.csv')\n",
    "    mapped_nodes_in_communities = list(itertools.chain(*communities.values()))\n",
    "    community_cosine_sim_df = cosine_sim_df.loc[mapped_nodes_in_communities][mapped_nodes_in_communities]\n",
    "    community_cosine_sim_df.to_csv(TV_SHOW + '_community_cosine_sim_frame'+ str(len(communities)) + \n",
    "                                   str(threshold_percentile_for_split)+ '.csv')\n",
    "    split_threshold = np.percentile(community_cosine_sim_df.values, threshold_percentile_for_split)\n",
    "    #splitting here\n",
    "    updated_communities = deepcopy(communities)\n",
    "    for seed_node, community in communities.items():\n",
    "      if len(community) == 1:\n",
    "        #print('Cannot split for community since it has community: {} since it has only one node'.format(community))\n",
    "        continue\n",
    "      else:\n",
    "        # split the community based on topic vectors within a community\n",
    "        for count_nodes, community_node in enumerate(community):\n",
    "          if community_node == seed_node:\n",
    "            continue\n",
    "          is_cos_dist_bigger_than_threshold = list(community_cosine_sim_df.loc[community_node] > split_threshold)\n",
    "          if False in is_cos_dist_bigger_than_threshold:\n",
    "            #print('Splitting node: {} from community: {}'.format(community_node, updated_communities[seed_node]))\n",
    "            updated_communities[community_node] = [community_node]\n",
    "            updated_communities[seed_node].remove(community_node)\n",
    "    \n",
    "    return updated_communities, community_cosine_sim_df, mapped_nodes_in_communities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_cosine_distance(comm1, community_cosine_sim_df, merge_threshold, mapped_nodes_in_communities):\n",
    "  if not isinstance(comm1, set):\n",
    "    comm1 = set(comm1)\n",
    "  remaining_list = list(set(mapped_nodes_in_communities)-comm1)\n",
    "  #print('*****',comm1)\n",
    "  min_cosine_dist_from_comm1 = community_cosine_sim_df[community_cosine_sim_df.index.isin(\n",
    "      list(comm1))][remaining_list].idxmax(axis=1).values\n",
    "  #print('*****',min_cosine_dist_from_comm1)\n",
    "  min_distance_list = []\n",
    "  for i in zip(comm1, min_cosine_dist_from_comm1):\n",
    "    min_distance_list.append(community_cosine_sim_df[i[0]][i[1]])\n",
    "  #print('*****',min_distance_list)\n",
    "  community_to_merge = None\n",
    "  if min(min_distance_list) > merge_threshold:\n",
    "    community_to_merge = min_cosine_dist_from_comm1[min_distance_list.index(min(min_distance_list))]\n",
    "  return community_to_merge\n",
    "\n",
    "def step3_merge_communities(updated_communities, community_cosine_sim_df, threshold_percentile_for_merge, \n",
    "                            mapped_nodes_in_communities):\n",
    "    \n",
    "    merge_threshold = np.percentile(community_cosine_sim_df.values, threshold_percentile_for_split)\n",
    "    test_communities = deepcopy(updated_communities)\n",
    "    #print(test_communities)\n",
    "    for seed_node, community in updated_communities.items():\n",
    "      if seed_node in test_communities:\n",
    "        community_to_merge_with_seed = get_min_cosine_distance(community, community_cosine_sim_df, \n",
    "                                                               merge_threshold, mapped_nodes_in_communities)\n",
    "        #print(seed_node, community_to_merge_with_seed)\n",
    "        if community_to_merge_with_seed:\n",
    "          seed_node_to_merge = [key for key, value in test_communities.items() \n",
    "                                if community_to_merge_with_seed in value][0]\n",
    "          #print(seed_node, test_communities)\n",
    "          merging_communities = test_communities.pop(seed_node_to_merge, None)\n",
    "          #print(seed_node, merging_communities)\n",
    "          if merging_communities:\n",
    "            test_communities[seed_node].extend(merging_communities)\n",
    "    \n",
    "    return test_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partitions(df, communities):\n",
    "    partitions = dict()\n",
    "\n",
    "    for k, v in communities.items():\n",
    "      for i in v:\n",
    "        partitions[int(i)] = int(k) \n",
    "        \n",
    "    for i in set(df.index)-set(partitions.keys()):\n",
    "        partitions[i] = i\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conductance(graph, partitions):\n",
    "  conductances_list = []\n",
    "  conductances_keys = []\n",
    "  for key, coms in partitions.items():\n",
    "    try:\n",
    "        conductances_list.append(nx.conductance(graph, coms))\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    else:\n",
    "        conductances_keys.append(key)\n",
    "  conductance_measures = dict(zip(conductances_keys, conductances_list))\n",
    "  if not conductance_measures:\n",
    "        return {}\n",
    "  return {'all_conductances': conductance_measures, 'min_conductance': min(conductance_measures.values()),\n",
    "          'max_conductance': max(conductance_measures.values()), \n",
    "          'avg_conductance': sum(conductance_measures.values())/len(partitions)}\n",
    "\n",
    "def get_triangle_participation_ratio(graph, partitions):\n",
    "  if nx.is_directed(graph):\n",
    "    graph = nx.to_undirected(graph)\n",
    "  tpr_measures = dict(zip(partitions.keys(), [triangle_participation_ratio(graph, coms) \n",
    "                                              for coms in partitions.values()]))\n",
    "  return {'all_tprs': tpr_measures, 'min_tpr': min(tpr_measures.values()),\n",
    "          'max_tpr': max(tpr_measures.values()), 'avg_tpr': sum(tpr_measures.values())/len(partitions)}\n",
    "\n",
    "\n",
    "def triangle_participation_ratio(graph, coms):\n",
    "  cls = nx.triangles(graph, coms)\n",
    "  #print(cls)\n",
    "  nc = [n for n in cls if cls[n] > 0]\n",
    "  #print(nc)\n",
    "  return float(len(nc))/len(coms)\n",
    "\n",
    "\n",
    "def get_community_modularity(graph, partitions):\n",
    "  modularities = {}\n",
    "  try:\n",
    "      modularities = {'modularity': nx.algorithms.community.modularity(graph, [set(com) \n",
    "                                                                               for com in partitions.values()])}\n",
    "  except:\n",
    "    return {}\n",
    "  return modularities\n",
    "\n",
    "def get_surprise(graph, partitions):\n",
    "  m = graph.number_of_edges()\n",
    "  n = graph.number_of_nodes()\n",
    "\n",
    "  q = 0\n",
    "  qa = 0\n",
    "  sp = 0\n",
    "\n",
    "  for community in partitions.values():\n",
    "      c = nx.subgraph(graph, community)\n",
    "      mc = c.number_of_edges()\n",
    "      nc = c.number_of_nodes()\n",
    "\n",
    "      q += mc\n",
    "      qa += scipy.special.comb(nc, 2, exact=True)\n",
    "  try:\n",
    "      q = q / m\n",
    "      qa = qa / scipy.special.comb(n, 2, exact=True)\n",
    "\n",
    "      sp = m * (q * np.log(q / qa) + (1 - q) * np.log2((1 - q) / (1 - qa)))\n",
    "  except ZeroDivisionError:\n",
    "      pass\n",
    "  return {'asymptotic_surprise': sp}\n",
    "\n",
    "def get_significance(graph, partitions):\n",
    "\n",
    "  m = graph.number_of_edges()\n",
    "\n",
    "  binom = scipy.special.comb(m, 2, exact=True)\n",
    "  p = m / binom\n",
    "\n",
    "  q = 0\n",
    "  #print(binom, p, q)\n",
    "\n",
    "  for community in partitions.values():\n",
    "      try:\n",
    "          c = nx.subgraph(graph, community)\n",
    "          nc = c.number_of_nodes()\n",
    "          mc = c.number_of_edges()\n",
    "\n",
    "          binom_c = scipy.special.comb(nc, 2, exact=True)\n",
    "          \n",
    "          pc = mc / binom_c\n",
    "          if pc < 1:\n",
    "              #print(community, nc, binom_c, pc, np.log((1 - pc) / (1 - p)))\n",
    "              q += binom_c * (pc * np.log(pc / p) + (1 - pc) * np.log((1 - pc) / (1 - p)))\n",
    "\n",
    "      except ZeroDivisionError:\n",
    "          pass\n",
    "  return {'significance': q}\n",
    "\n",
    "def get_number_communities(partitions):\n",
    "    if isinstance(partitions, dict):\n",
    "        return {'num_communities': len(partitions)}\n",
    "    else:\n",
    "        return {'num_communities': None }\n",
    "\n",
    "def get_communities(partitions):\n",
    "    if isinstance(partitions, dict):\n",
    "        return {'communities': partitions }\n",
    "    else:\n",
    "        return {'communities': None }\n",
    "    \n",
    "def get_evaluation_metrics(graph, partitions):\n",
    "  return dict(chain(get_communities(partitions).items(), \n",
    "                    get_number_communities(partitions).items(),\n",
    "                    get_conductance(graph, partitions).items(), \n",
    "                    get_triangle_participation_ratio(graph, partitions).items(), \n",
    "                    get_community_modularity(graph, partitions).items(), \n",
    "                    get_surprise(graph, partitions).items(),\n",
    "                    get_significance(graph, partitions).items())\n",
    "             )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouNetflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 14660\n",
      "Number of edges: 13932\n",
      "Average in degree:   0.9503\n",
      "Average out degree:   0.9503\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 14660\n",
      "Number of edges: 13932\n",
      "Average in degree:   0.9503\n",
      "Average out degree:   0.9503\n",
      "\n",
      "Isolated nodes: 2065\n",
      "\n",
      "removing isolated nodes...\n",
      "\n",
      "[5, 25, 125, 625, 3125]\n",
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of influential nodes: 3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_INFLUENTIAL_NODES = 100\n",
    "threshold_percentile_for_merge = 25\n",
    "threshold_percentile_for_split = 25\n",
    "\n",
    "you_graph = load_graph(GRAPHML_FILE)\n",
    "you_graph = remove_isolated_nodes(you_graph)\n",
    "you_graph = add_weights(you_graph)\n",
    "you_graph = nx.relabel_nodes(you_graph, lambda x:int(x))\n",
    "\n",
    "evaluation_scores = {}\n",
    "num_nodes = [5**i for i in range(1, you_graph.number_of_nodes()) if 5**i < 100000]\n",
    "print(num_nodes)\n",
    "for node_range in num_nodes:\n",
    "    for threshold in [10, 25, 50, 75, 100] :\n",
    "        you_topic_vec_df = get_topic_frame(TOPIC_VEC_FILE, GRAPH_NODE_FILE)\n",
    "        you_twitter_rank_df = get_topic_frame(TWITTER_RANK_FILE, GRAPH_NODE_FILE)\n",
    "        you_influential_nodes = get_influential_nodes(you_graph, you_topic_vec_df, you_twitter_rank_df, \n",
    "                                                      num_topics=NUM_TOPICS, num_of_influential_nodes=node_range)\n",
    "        print('length of influential nodes: {}'.format(len(you_influential_nodes)))\n",
    "        you_initial_communities = step1_assign_initial_communities(you_graph, you_topic_vec_df, \n",
    "                                                                   you_influential_nodes)\n",
    "        cosine_sim_df = get_cosine_sim_df(you_topic_vec_df)\n",
    "        communities_after_split, community_cosine_sim_df, mapped_nodes = step2_split_community(\n",
    "            you_initial_communities, threshold, cosine_sim_df)\n",
    "        you_communties_after_merge = step3_merge_communities(communities_after_split, community_cosine_sim_df,\n",
    "                                                 threshold, mapped_nodes)\n",
    "        you_partitions = make_partitions(you_topic_vec_df, you_communties_after_merge)\n",
    "        you_coms_dict = deepcopy(you_communties_after_merge)\n",
    "        evaluation_scores['num_nodes_{}_threshold_{}'.format(node_range, threshold)] = get_evaluation_metrics(\n",
    "            you_graph, you_coms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_list = ['num_communities', 'min_conductance', 'max_conductance', 'avg_conductance', 'asymptotic_surprise',\n",
    "              'significance']\n",
    "eval_df = pd.DataFrame.from_dict(evaluation_scores, orient='index', columns=column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_index(ascending=True, axis=1)\n",
    "eval_df['length'] = eval_df.index.str.len()\n",
    "eval_df.sort_values('length', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all community Detection Algorithms\n",
    "from igraph import *\n",
    "\n",
    "\n",
    "        \n",
    "def describe(G, comms):\n",
    "    print('Number of nodes: ', G.vcount())\n",
    "    print('Number of edges: ', G.ecount())\n",
    "    print(describe(self.G))\n",
    "\n",
    "def remove_self_loops(G, weights=None):\n",
    "    # If graph has self-loops, remove the self-loops\n",
    "    if not G.is_simple():\n",
    "        G = G.simplify(loops = True, multiple = True, \n",
    "                                 combine_edges = dict(weight=weights))\n",
    "    return G\n",
    "\n",
    "\n",
    "def convert_to_undirected(g, weights=None):\n",
    "    # If graph is directed, convert to undirected\n",
    "    #print(summary(g))\n",
    "    if g.is_directed():\n",
    "        g =  g.as_undirected(mode = 'collapse', combine_edges = \"sum\")\n",
    "    return g\n",
    "\n",
    "def fast_greedy(G, weights=None):\n",
    "    g = G.copy()\n",
    "    g = convert_to_undirected(g)\n",
    "    summary(g)\n",
    "    comms = g.community_fastgreedy(weights=weights)\n",
    "    print('Number of communities: ', comms.optimal_count)\n",
    "    return comms\n",
    "\n",
    "def edge_betweenness(G, weights=None):\n",
    "    g = G.copy()\n",
    "    comms = g.community_edge_betweenness(clusters=None, directed=True, weights=weights)\n",
    "    print('Number of communities: ', comms.optimal_count)\n",
    "    return comms\n",
    "\n",
    "def infomap(G, edge_weights=None, vertex_weights=None, trials=10):\n",
    "    g = G.copy()\n",
    "    comms = g.community_infomap(edge_weights=edge_weights, vertex_weights=vertex_weights, trials=10)\n",
    "    print('Number of communities: ', comms._len)\n",
    "    return comms\n",
    "\n",
    "def label_propagation(G, weights=None, initial=None, fixed=None):\n",
    "    g = G.copy()\n",
    "    comms = g.community_label_propagation(weights=weights, initial=initial, fixed=fixed)\n",
    "    print('Number of communities: ', comms._len)\n",
    "    return comms\n",
    "\n",
    "def leading_eigen_vector(G, clusters=-1, arpack_options=None, weights=None):\n",
    "    g = G.copy()\n",
    "    g = convert_to_undirected(g)\n",
    "    comms = g.community_leading_eigenvector(clusters=clusters, arpack_options=arpack_options, weights=weights)\n",
    "    print('Number of communities: ', comms._len)\n",
    "    return comms\n",
    "\n",
    "def multilevel(G, weights=None, return_levels=True):\n",
    "    g = G.copy()\n",
    "    g = convert_to_undirected(g)\n",
    "    summary(g)\n",
    "    #print(summary(g))\n",
    "    comms = g.community_multilevel(weights=weights, return_levels=return_levels)\n",
    "    print('Number of communities: ', len(comms))\n",
    "    return comms\n",
    "\n",
    "def optimal_modularity(G, weights=None):\n",
    "    g = G.copy()\n",
    "    g = convert_to_undirected(g)\n",
    "    print(summary(g))\n",
    "    #g = self.convert_to_undirected(g)\n",
    "    #print(summary(g))\n",
    "    comms = g.community_optimal_modularity(weights=weights)\n",
    "    print('Number of communities: ', comms._len)\n",
    "    return comms\n",
    "\n",
    "def spinglass(G, weights=None, spins=25, parupdate=False, start_temp=1, stop_temp=0.01,\n",
    "              cool_fact=0.99, update_rule=\"simple\", gamma=1, implementation=\"orig\"):\n",
    "    g = G.copy()\n",
    "    comms = g.community_spinglass(weights=weights, spins=spins, parupdate=parupdate, start_temp=start_temp,\n",
    "                                 stop_temp=stop_temp, cool_fact=cool_fact, update_rule=update_rule, gamma=gamma,\n",
    "                                 implementation=implementation)\n",
    "    print('Number of communities: ', comms._len)\n",
    "    return comms\n",
    "\n",
    "\n",
    "def walktrap(G, weights=None, steps=4):\n",
    "    g = G.copy()\n",
    "    #g = self.convert_to_undirected(g)\n",
    "    summary(g)\n",
    "    comms = g.community_walktrap(weights=weights, steps=steps)\n",
    "    print('Number of communities: ', comms.optimal_count)\n",
    "    return comms\n",
    "\n",
    "def louvain(G):\n",
    "    # TO DO: use python-louvain to implement louvain algorithm\n",
    "    pass\n",
    "\n",
    "def leiden(G):\n",
    "    # TO DO: use python-leidenalg to implement louvain algorithm\n",
    "    pass\n",
    "\n",
    "def plot_communities(G, comms):\n",
    "    visual_style = {}\n",
    "    visual_style[\"vertex_size\"] = 10\n",
    "    #visual_style[\"vertex_label\"] = graph.vs[\"id\"]\n",
    "    visual_style['edge_arrow_size'] = 0.5\n",
    "    visual_style[\"layout\"] = G.layout('fr')\n",
    "    plot(comms, **visual_style)\n",
    "\n",
    "def modularity(G, clustering_algorithm):\n",
    "    return G.modularity(clustering_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_graph(you_graph, 'YouNetflix_preprocessed.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH D-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n"
     ]
    }
   ],
   "source": [
    "community_graph = Graph.Read_GraphML('YouNetflix_preprocessed.graphml')\n",
    "summary(community_graph)\n",
    "# visual_style = {}\n",
    "# visual_style[\"vertex_size\"] = 10\n",
    "# #visual_style[\"vertex_label\"] = graph.vs[\"id\"]\n",
    "# visual_style['edge_arrow_size'] = 0.5\n",
    "# visual_style[\"layout\"] = graph.layout('fr')\n",
    "# plot(graph, mark_groups=True, **visual_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  6025\n"
     ]
    }
   ],
   "source": [
    "edge_betweenness_comms_with_weights = edge_betweenness(community_graph, weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  6140\n"
     ]
    }
   ],
   "source": [
    "edge_betweenness_comms = edge_betweenness(community_graph, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  13\n"
     ]
    }
   ],
   "source": [
    "fast_greedy_comms = fast_greedy(community_graph, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  13\n"
     ]
    }
   ],
   "source": [
    "fast_greedy_comms_with_weights = fast_greedy(community_graph, weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  1\n"
     ]
    }
   ],
   "source": [
    "infomap_comms = infomap(community_graph, edge_weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  1\n"
     ]
    }
   ],
   "source": [
    "infomap_comms_with_weights = infomap(community_graph, edge_weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  729\n"
     ]
    }
   ],
   "source": [
    "label_prop_comms = label_propagation(community_graph, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  729\n"
     ]
    }
   ],
   "source": [
    "label_prop_comms_with_weights = label_propagation(community_graph, weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  10\n"
     ]
    }
   ],
   "source": [
    "leading_eigenvector_comms = leading_eigen_vector(community_graph, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities:  17\n"
     ]
    }
   ],
   "source": [
    "leading_eigenvector_comms_with_weights = leading_eigen_vector(community_graph, weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  13\n"
     ]
    }
   ],
   "source": [
    "multilevel_comms = multilevel(community_graph, weights = None, return_levels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  13\n"
     ]
    }
   ],
   "source": [
    "multilevel_comms_with_weights = multilevel(community_graph, weights = 'weight', return_levels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giant_sub_graph = graph.clusters().giant()\n",
    "# community_sub_graph = Communities(giant_sub_graph)\n",
    "# spinglass_comms = community_sub_graph.spinglass(weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spinglass_comms_with_weights = community_sub_graph.spinglass(weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH D-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  11\n"
     ]
    }
   ],
   "source": [
    "walktrap_comms = walktrap(community_graph, weights = None, steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH D-W- 12595 13932 -- \n",
      "+ attr: create_time (v), id (v), create_time (e), mention_count (e), quote_count (e), reply_count (e), retweet_count (e), weight (e)\n",
      "Number of communities:  13\n"
     ]
    }
   ],
   "source": [
    "walktrap_comms_with_weights = walktrap(community_graph, weights = 'weight', steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_communities</th>\n",
       "      <th>min_conductance</th>\n",
       "      <th>max_conductance</th>\n",
       "      <th>avg_conductance</th>\n",
       "      <th>asymptotic_surprise</th>\n",
       "      <th>significance</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_nodes_5_threshold_75</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>31.590904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_5_threshold_50</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>31.590904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_5_threshold_25</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>31.590904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_5_threshold_10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>31.590904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_25_threshold_10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>130.132922</td>\n",
       "      <td>114.992713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_25_threshold_25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>130.132922</td>\n",
       "      <td>114.992713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_25_threshold_50</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>130.132922</td>\n",
       "      <td>114.992713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_25_threshold_75</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>130.132922</td>\n",
       "      <td>114.992713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_5_threshold_100</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>31.590904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_125_threshold_10</th>\n",
       "      <td>125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_625_threshold_25</th>\n",
       "      <td>625</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_625_threshold_10</th>\n",
       "      <td>625</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_625_threshold_75</th>\n",
       "      <td>625</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_25_threshold_100</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>130.132922</td>\n",
       "      <td>114.992713</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_125_threshold_75</th>\n",
       "      <td>125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_125_threshold_50</th>\n",
       "      <td>125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_125_threshold_25</th>\n",
       "      <td>125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_625_threshold_50</th>\n",
       "      <td>625</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_3125_threshold_50</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_3125_threshold_75</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_3125_threshold_10</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_625_threshold_100</th>\n",
       "      <td>625</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_125_threshold_100</th>\n",
       "      <td>125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_3125_threshold_25</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_nodes_3125_threshold_100</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              num_communities  min_conductance  \\\n",
       "num_nodes_5_threshold_75                    3         0.998775   \n",
       "num_nodes_5_threshold_50                    3         0.998775   \n",
       "num_nodes_5_threshold_25                    3         0.998775   \n",
       "num_nodes_5_threshold_10                    3         0.998775   \n",
       "num_nodes_25_threshold_10                   4         0.994233   \n",
       "num_nodes_25_threshold_25                   4         0.994233   \n",
       "num_nodes_25_threshold_50                   4         0.994233   \n",
       "num_nodes_25_threshold_75                   4         0.994233   \n",
       "num_nodes_5_threshold_100                   3         0.998775   \n",
       "num_nodes_125_threshold_10                125         0.993243   \n",
       "num_nodes_625_threshold_25                625         0.993243   \n",
       "num_nodes_625_threshold_10                625         0.993243   \n",
       "num_nodes_625_threshold_75                625         0.993243   \n",
       "num_nodes_25_threshold_100                  4         0.994233   \n",
       "num_nodes_125_threshold_75                125         0.993243   \n",
       "num_nodes_125_threshold_50                125         0.993243   \n",
       "num_nodes_125_threshold_25                125         0.993243   \n",
       "num_nodes_625_threshold_50                625         0.993243   \n",
       "num_nodes_3125_threshold_50              3125         0.993243   \n",
       "num_nodes_3125_threshold_75              3125         0.993243   \n",
       "num_nodes_3125_threshold_10              3125         0.993243   \n",
       "num_nodes_625_threshold_100               625         0.993243   \n",
       "num_nodes_125_threshold_100               125         0.993243   \n",
       "num_nodes_3125_threshold_25              3125         0.993243   \n",
       "num_nodes_3125_threshold_100             3125         0.993243   \n",
       "\n",
       "                              max_conductance  avg_conductance  \\\n",
       "num_nodes_5_threshold_75             0.999597         0.999221   \n",
       "num_nodes_5_threshold_50             0.999597         0.999221   \n",
       "num_nodes_5_threshold_25             0.999597         0.999221   \n",
       "num_nodes_5_threshold_10             0.999597         0.999221   \n",
       "num_nodes_25_threshold_10            0.999455         0.998040   \n",
       "num_nodes_25_threshold_25            0.999455         0.998040   \n",
       "num_nodes_25_threshold_50            0.999455         0.998040   \n",
       "num_nodes_25_threshold_75            0.999455         0.998040   \n",
       "num_nodes_5_threshold_100            0.999597         0.999221   \n",
       "num_nodes_125_threshold_10           1.000000         0.087880   \n",
       "num_nodes_625_threshold_25           1.000000         0.017576   \n",
       "num_nodes_625_threshold_10           1.000000         0.017576   \n",
       "num_nodes_625_threshold_75           1.000000         0.017576   \n",
       "num_nodes_25_threshold_100           0.999455         0.998040   \n",
       "num_nodes_125_threshold_75           1.000000         0.087880   \n",
       "num_nodes_125_threshold_50           1.000000         0.087880   \n",
       "num_nodes_125_threshold_25           1.000000         0.087880   \n",
       "num_nodes_625_threshold_50           1.000000         0.017576   \n",
       "num_nodes_3125_threshold_50          1.000000         0.003515   \n",
       "num_nodes_3125_threshold_75          1.000000         0.003515   \n",
       "num_nodes_3125_threshold_10          1.000000         0.003515   \n",
       "num_nodes_625_threshold_100          1.000000         0.017576   \n",
       "num_nodes_125_threshold_100          1.000000         0.087880   \n",
       "num_nodes_3125_threshold_25          1.000000         0.003515   \n",
       "num_nodes_3125_threshold_100         1.000000         0.003515   \n",
       "\n",
       "                              asymptotic_surprise  significance  length  \n",
       "num_nodes_5_threshold_75                31.590904      0.000000      24  \n",
       "num_nodes_5_threshold_50                31.590904      0.000000      24  \n",
       "num_nodes_5_threshold_25                31.590904      0.000000      24  \n",
       "num_nodes_5_threshold_10                31.590904      0.000000      24  \n",
       "num_nodes_25_threshold_10              130.132922    114.992713      25  \n",
       "num_nodes_25_threshold_25              130.132922    114.992713      25  \n",
       "num_nodes_25_threshold_50              130.132922    114.992713      25  \n",
       "num_nodes_25_threshold_75              130.132922    114.992713      25  \n",
       "num_nodes_5_threshold_100               31.590904      0.000000      25  \n",
       "num_nodes_125_threshold_10               0.000000      0.000000      26  \n",
       "num_nodes_625_threshold_25               0.000000      0.000000      26  \n",
       "num_nodes_625_threshold_10               0.000000      0.000000      26  \n",
       "num_nodes_625_threshold_75               0.000000      0.000000      26  \n",
       "num_nodes_25_threshold_100             130.132922    114.992713      26  \n",
       "num_nodes_125_threshold_75               0.000000      0.000000      26  \n",
       "num_nodes_125_threshold_50               0.000000      0.000000      26  \n",
       "num_nodes_125_threshold_25               0.000000      0.000000      26  \n",
       "num_nodes_625_threshold_50               0.000000      0.000000      26  \n",
       "num_nodes_3125_threshold_50              0.000000      0.000000      27  \n",
       "num_nodes_3125_threshold_75              0.000000      0.000000      27  \n",
       "num_nodes_3125_threshold_10              0.000000      0.000000      27  \n",
       "num_nodes_625_threshold_100              0.000000      0.000000      27  \n",
       "num_nodes_125_threshold_100              0.000000      0.000000      27  \n",
       "num_nodes_3125_threshold_25              0.000000      0.000000      27  \n",
       "num_nodes_3125_threshold_100             0.000000      0.000000      28  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__plot__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_convert_matrix_to_tuple_repr',\n",
       " '_graph',\n",
       " '_item_box_size',\n",
       " '_merges',\n",
       " '_modularity_params',\n",
       " '_names',\n",
       " '_nitems',\n",
       " '_nmerges',\n",
       " '_optimal_count',\n",
       " '_plot_item',\n",
       " '_traverse_inorder',\n",
       " 'as_clustering',\n",
       " 'format',\n",
       " 'merges',\n",
       " 'names',\n",
       " 'optimal_count',\n",
       " 'summary']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_betweenness_comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<igraph.clustering.VertexClustering at 0x12b2ca9d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_betweenness_comms.as_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adjacency',\n",
       " 'Asymmetric_Preference',\n",
       " 'Atlas',\n",
       " 'Barabasi',\n",
       " 'Bipartite',\n",
       " 'De_Bruijn',\n",
       " 'Degree_Sequence',\n",
       " 'DictList',\n",
       " 'Erdos_Renyi',\n",
       " 'Establishment',\n",
       " 'Famous',\n",
       " 'Forest_Fire',\n",
       " 'Formula',\n",
       " 'Full',\n",
       " 'Full_Bipartite',\n",
       " 'Full_Citation',\n",
       " 'GRG',\n",
       " 'Growing_Random',\n",
       " 'Incidence',\n",
       " 'Isoclass',\n",
       " 'K_Regular',\n",
       " 'Kautz',\n",
       " 'LCF',\n",
       " 'Lattice',\n",
       " 'Load',\n",
       " 'Preference',\n",
       " 'Random_Bipartite',\n",
       " 'Read',\n",
       " 'Read_Adjacency',\n",
       " 'Read_DIMACS',\n",
       " 'Read_DL',\n",
       " 'Read_Edgelist',\n",
       " 'Read_GML',\n",
       " 'Read_GraphDB',\n",
       " 'Read_GraphML',\n",
       " 'Read_GraphMLz',\n",
       " 'Read_Lgl',\n",
       " 'Read_Ncol',\n",
       " 'Read_Pajek',\n",
       " 'Read_Pickle',\n",
       " 'Read_Picklez',\n",
       " 'Recent_Degree',\n",
       " 'Ring',\n",
       " 'SBM',\n",
       " 'Star',\n",
       " 'Static_Fitness',\n",
       " 'Static_Power_Law',\n",
       " 'Tree',\n",
       " 'TupleList',\n",
       " 'Watts_Strogatz',\n",
       " 'Weighted_Adjacency',\n",
       " '_Bipartite',\n",
       " '_Full_Bipartite',\n",
       " '_GRG',\n",
       " '_Incidence',\n",
       " '_Random_Bipartite',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__coerce__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__graph_as_capsule',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__isub__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__plot__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__register_destructor',\n",
       " '__repr__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '_as_parameter_',\n",
       " '_format_mapping',\n",
       " '_identify_format',\n",
       " '_is_matching',\n",
       " '_is_maximal_matching',\n",
       " '_layout_mapping',\n",
       " '_layout_sugiyama',\n",
       " '_maximum_bipartite_matching',\n",
       " '_raw_pointer',\n",
       " '_reconstruct',\n",
       " '_spanning_tree',\n",
       " 'add_edge',\n",
       " 'add_edges',\n",
       " 'add_vertex',\n",
       " 'add_vertices',\n",
       " 'adhesion',\n",
       " 'adjacent',\n",
       " 'all_minimal_st_separators',\n",
       " 'all_st_cuts',\n",
       " 'all_st_mincuts',\n",
       " 'alpha',\n",
       " 'are_connected',\n",
       " 'articulation_points',\n",
       " 'as_directed',\n",
       " 'as_undirected',\n",
       " 'assortativity',\n",
       " 'assortativity_degree',\n",
       " 'assortativity_nominal',\n",
       " 'attributes',\n",
       " 'authority_score',\n",
       " 'average_path_length',\n",
       " 'betweenness',\n",
       " 'bfs',\n",
       " 'bfsiter',\n",
       " 'bibcoupling',\n",
       " 'biconnected_components',\n",
       " 'bipartite_projection',\n",
       " 'bipartite_projection_size',\n",
       " 'blocks',\n",
       " 'canonical_permutation',\n",
       " 'clique_number',\n",
       " 'cliques',\n",
       " 'closeness',\n",
       " 'clusters',\n",
       " 'cocitation',\n",
       " 'cohesion',\n",
       " 'cohesive_blocks',\n",
       " 'community_edge_betweenness',\n",
       " 'community_fastgreedy',\n",
       " 'community_infomap',\n",
       " 'community_label_propagation',\n",
       " 'community_leading_eigenvector',\n",
       " 'community_leading_eigenvector_naive',\n",
       " 'community_multilevel',\n",
       " 'community_optimal_modularity',\n",
       " 'community_spinglass',\n",
       " 'community_walktrap',\n",
       " 'complementer',\n",
       " 'components',\n",
       " 'compose',\n",
       " 'constraint',\n",
       " 'contract_vertices',\n",
       " 'convergence_degree',\n",
       " 'convergence_field_size',\n",
       " 'copy',\n",
       " 'coreness',\n",
       " 'count_automorphisms_vf2',\n",
       " 'count_isomorphisms_vf2',\n",
       " 'count_multiple',\n",
       " 'count_subisomorphisms_vf2',\n",
       " 'cut_vertices',\n",
       " 'decompose',\n",
       " 'degree',\n",
       " 'degree_distribution',\n",
       " 'delete_edges',\n",
       " 'delete_vertices',\n",
       " 'density',\n",
       " 'diameter',\n",
       " 'difference',\n",
       " 'disjoint_union',\n",
       " 'diversity',\n",
       " 'dyad_census',\n",
       " 'eccentricity',\n",
       " 'ecount',\n",
       " 'edge_attributes',\n",
       " 'edge_betweenness',\n",
       " 'edge_connectivity',\n",
       " 'edge_disjoint_paths',\n",
       " 'eigen_adjacency',\n",
       " 'eigenvector_centrality',\n",
       " 'es',\n",
       " 'evcent',\n",
       " 'farthest_points',\n",
       " 'feedback_arc_set',\n",
       " 'get_adjacency',\n",
       " 'get_adjedgelist',\n",
       " 'get_adjlist',\n",
       " 'get_all_shortest_paths',\n",
       " 'get_automorphisms_vf2',\n",
       " 'get_diameter',\n",
       " 'get_edgelist',\n",
       " 'get_eid',\n",
       " 'get_eids',\n",
       " 'get_incidence',\n",
       " 'get_inclist',\n",
       " 'get_isomorphisms_vf2',\n",
       " 'get_shortest_paths',\n",
       " 'get_subisomorphisms_lad',\n",
       " 'get_subisomorphisms_vf2',\n",
       " 'girth',\n",
       " 'gomory_hu_tree',\n",
       " 'has_multiple',\n",
       " 'hub_score',\n",
       " 'incident',\n",
       " 'indegree',\n",
       " 'independence_number',\n",
       " 'independent_vertex_sets',\n",
       " 'induced_subgraph',\n",
       " 'intersection',\n",
       " 'is_bipartite',\n",
       " 'is_connected',\n",
       " 'is_dag',\n",
       " 'is_directed',\n",
       " 'is_loop',\n",
       " 'is_minimal_separator',\n",
       " 'is_multiple',\n",
       " 'is_mutual',\n",
       " 'is_named',\n",
       " 'is_separator',\n",
       " 'is_simple',\n",
       " 'is_weighted',\n",
       " 'isoclass',\n",
       " 'isomorphic',\n",
       " 'isomorphic_bliss',\n",
       " 'isomorphic_vf2',\n",
       " 'k_core',\n",
       " 'knn',\n",
       " 'laplacian',\n",
       " 'largest_cliques',\n",
       " 'largest_independent_vertex_sets',\n",
       " 'layout',\n",
       " 'layout_auto',\n",
       " 'layout_bipartite',\n",
       " 'layout_circle',\n",
       " 'layout_drl',\n",
       " 'layout_fruchterman_reingold',\n",
       " 'layout_fruchterman_reingold_3d',\n",
       " 'layout_graphopt',\n",
       " 'layout_grid',\n",
       " 'layout_grid_3d',\n",
       " 'layout_grid_fruchterman_reingold',\n",
       " 'layout_kamada_kawai',\n",
       " 'layout_kamada_kawai_3d',\n",
       " 'layout_lgl',\n",
       " 'layout_mds',\n",
       " 'layout_random',\n",
       " 'layout_random_3d',\n",
       " 'layout_reingold_tilford',\n",
       " 'layout_reingold_tilford_circular',\n",
       " 'layout_sphere',\n",
       " 'layout_star',\n",
       " 'layout_sugiyama',\n",
       " 'linegraph',\n",
       " 'maxdegree',\n",
       " 'maxflow',\n",
       " 'maxflow_value',\n",
       " 'maximal_cliques',\n",
       " 'maximal_independent_vertex_sets',\n",
       " 'maximum_bipartite_matching',\n",
       " 'mincut',\n",
       " 'mincut_value',\n",
       " 'minimum_size_separators',\n",
       " 'modularity',\n",
       " 'motifs_randesu',\n",
       " 'motifs_randesu_estimate',\n",
       " 'motifs_randesu_no',\n",
       " 'neighborhood',\n",
       " 'neighborhood_size',\n",
       " 'neighbors',\n",
       " 'omega',\n",
       " 'outdegree',\n",
       " 'pagerank',\n",
       " 'path_length_hist',\n",
       " 'permute_vertices',\n",
       " 'personalized_pagerank',\n",
       " 'predecessors',\n",
       " 'radius',\n",
       " 'reciprocity',\n",
       " 'rewire',\n",
       " 'rewire_edges',\n",
       " 'save',\n",
       " 'shell_index',\n",
       " 'shortest_paths',\n",
       " 'shortest_paths_dijkstra',\n",
       " 'similarity_dice',\n",
       " 'similarity_inverse_log_weighted',\n",
       " 'similarity_jaccard',\n",
       " 'simplify',\n",
       " 'spanning_tree',\n",
       " 'st_mincut',\n",
       " 'strength',\n",
       " 'subcomponent',\n",
       " 'subgraph',\n",
       " 'subgraph_edges',\n",
       " 'subisomorphic_lad',\n",
       " 'subisomorphic_vf2',\n",
       " 'successors',\n",
       " 'summary',\n",
       " 'to_directed',\n",
       " 'to_undirected',\n",
       " 'topological_sorting',\n",
       " 'transitivity_avglocal_undirected',\n",
       " 'transitivity_local_undirected',\n",
       " 'transitivity_undirected',\n",
       " 'triad_census',\n",
       " 'unfold_tree',\n",
       " 'union',\n",
       " 'vcount',\n",
       " 'vertex_attributes',\n",
       " 'vertex_connectivity',\n",
       " 'vertex_disjoint_paths',\n",
       " 'vs',\n",
       " 'write',\n",
       " 'write_adjacency',\n",
       " 'write_dimacs',\n",
       " 'write_dot',\n",
       " 'write_edgelist',\n",
       " 'write_gml',\n",
       " 'write_graphml',\n",
       " 'write_graphmlz',\n",
       " 'write_leda',\n",
       " 'write_lgl',\n",
       " 'write_ncol',\n",
       " 'write_pajek',\n",
       " 'write_pickle',\n",
       " 'write_picklez',\n",
       " 'write_svg']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__plot__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_convert_matrix_to_tuple_repr',\n",
       " '_graph',\n",
       " '_item_box_size',\n",
       " '_merges',\n",
       " '_modularity_params',\n",
       " '_names',\n",
       " '_nitems',\n",
       " '_nmerges',\n",
       " '_optimal_count',\n",
       " '_plot_item',\n",
       " '_traverse_inorder',\n",
       " 'as_clustering',\n",
       " 'format',\n",
       " 'merges',\n",
       " 'names',\n",
       " 'optimal_count',\n",
       " 'summary']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(edge_betweenness_comms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infomap_comms.modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_algorithms = [edge_betweenness_comms, edge_betweenness_comms_with_weights, fast_greedy, fast_greedy_comms, \n",
    "                  infomap_comms, infomap_comms_with_weights, label_prop_comms, label_prop_comms_with_weights,\n",
    "                  leading_eigenvector_comms, leading_eigenvector_comms_with_weights, multilevel_comms,\n",
    "                  multilevel_comms_with_weights, walktrap_comms, walktrap_comms_with_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for com_algo in com_algorithms:\n",
    "    try:\n",
    "        print('Community: {}, Modularity: {}'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "integer too large for conversion to C int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-efdce8b22499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalktrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myou_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/cdlib/algorithms/crisp_partition.py\u001b[0m in \u001b[0;36mwalktrap\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optional dependency not satisfied: install igraph to use the selected feature.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_graph_formats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0mcoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity_walktrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mcommunities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/cdlib/utils.py\u001b[0m in \u001b[0;36mconvert_graph_formats\u001b[0;34m(graph, desired_format, directed)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m__from_igraph_to_nx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdesired_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m__from_nx_to_igraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The graph object should be either a networkx or an igraph one.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/cdlib/utils.py\u001b[0m in \u001b[0;36m__from_nx_to_igraph\u001b[0;34m(g, directed)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36madd_edges\u001b[0;34m(self, es)\u001b[0m\n\u001b[1;32m    253\u001b[0m           \u001b[0mendpoints\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mVertices\u001b[0m \u001b[0mare\u001b[0m \u001b[0menumerated\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGraphBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_vertex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: integer too large for conversion to C int"
     ]
    }
   ],
   "source": [
    "coms = algorithms.walktrap(you_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1048650\n",
      "Number of edges: 3369021\n",
      "Average in degree:   3.2127\n",
      "Average out degree:   3.2127\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1048650\n",
      "Number of edges: 3369021\n",
      "Average in degree:   3.2127\n",
      "Average out degree:   3.2127\n",
      "\n",
      "Isolated nodes: 112586\n",
      "\n",
      "removing isolated nodes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "you_new_graph = load_graph(GRAPHML_FILE)\n",
    "you_new_graph = remove_isolated_nodes(you_new_graph)\n",
    "you_new_graph = add_weights(you_new_graph)\n",
    "you_new_graph = nx.relabel_nodes(you_new_graph, lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936064"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 25, 125, 625, 3125, 15625]\n",
      "length of influential nodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/soumithri/.local/share/virtualenvs/Thesis-cQCF3LGF/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "evaluation_scores = {}\n",
    "#total_nodes = you_new_graph.number_of_nodes()\n",
    "#num_nodes = [5**i for i in range(1, total_nodes) if 5**i < 100000]\n",
    "num_nodes = [5, 25, 125, 625, 3125, 15625]\n",
    "print(num_nodes)\n",
    "for node_range in num_nodes:\n",
    "    for threshold in [10, 25, 50, 75, 100] :\n",
    "        you_new_topic_vec_df = get_topic_frame(TOPIC_VEC_FILE, GRAPH_NODE_FILE)\n",
    "        you_new_twitter_rank_df = get_topic_frame(TWITTER_RANK_FILE, GRAPH_NODE_FILE)\n",
    "        you_new_influential_nodes = get_influential_nodes(you_new_graph, \n",
    "                                                          you_new_topic_vec_df, \n",
    "                                                          you_new_twitter_rank_df, \n",
    "                                                          num_topics=NUM_TOPICS, \n",
    "                                                          num_of_influential_nodes=node_range)\n",
    "        print('length of influential nodes: {}'.format(len(you_new_influential_nodes)))\n",
    "        you_new_initial_communities = step1_assign_initial_communities(you_new_graph, you_new_topic_vec_df, \n",
    "                                                                   you_new_influential_nodes)\n",
    "        cosine_sim_df = get_cosine_sim_df(you_new_topic_vec_df)\n",
    "        communities_after_split, community_cosine_sim_df, mapped_nodes = step2_split_community(\n",
    "            you_new_initial_communities, threshold, cosine_sim_df)\n",
    "        you_new_communties_after_merge = step3_merge_communities(communities_after_split, community_cosine_sim_df,\n",
    "                                                 threshold, mapped_nodes)\n",
    "        you_new_partitions = make_partitions(you_new_topic_vec_df, you_new_communties_after_merge)\n",
    "        you_new_coms_dict = deepcopy(you_new_communties_after_merge)\n",
    "        evaluation_scores['num_nodes_{}_threshold_{}'.format(node_range, threshold)] = get_evaluation_metrics(\n",
    "            you_new_graph, you_new_coms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
